{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------------------------------------------------------------------------------------------------\n",
    "# By Alexandra Lee (July 2018) \n",
    "#\n",
    "# Encode Pseudomonas gene expression data into low dimensional latent space using \n",
    "# Tybalt with multiple hidden layers\n",
    "# --------------------------------------------------------------------------------------------------------------------\n",
    "import os\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.layers import Input, Dense, Lambda, Layer, Activation\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model, Sequential\n",
    "from keras import backend as K\n",
    "from keras import metrics, optimizers\n",
    "from keras.callbacks import Callback\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------------------------------------------------------\n",
    "# Files\n",
    "# --------------------------------------------------------------------------------------------------------------------\n",
    "data_file =  os.path.join(os.path.dirname(os.getcwd()), \"data\", \"all-pseudomonas-gene-normalized.pcl\")\n",
    "rnaseq = pd.read_table(data_file,sep='\\t',index_col=0)\n",
    "rnaseq = rnaseq.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------------------------------------------------------\n",
    "# Initialize hyper parameters\n",
    "#\n",
    "# learning rate: \n",
    "# batch size: Total number of training examples present in a single batch\n",
    "#             Iterations is the number of batches needed to complete one epoch\n",
    "# epochs: One Epoch is when an ENTIRE dataset is passed forward and backward through the neural network only ONCE\n",
    "# kappa: warmup\n",
    "# original dim: dimensions of the raw data\n",
    "# latent dim: dimensiosn of the latent space (fixed by the user)\n",
    "#   Note: intrinsic latent space dimension unknown\n",
    "# epsilon std: \n",
    "# beta: Threshold value for ReLU?\n",
    "# --------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "learning_rate = 0.001\n",
    "batch_size = 50\n",
    "epochs = 100\n",
    "kappa = 0.01\n",
    "\n",
    "original_dim = rnaseq.shape[1]\n",
    "intermediate_dim = 100\n",
    "latent_dim = 10\n",
    "epsilon_std = 1.0\n",
    "beta = K.variable(0)\n",
    "\n",
    "stat_file =  os.path.join(os.path.dirname(os.getcwd()), \"stats\", \"tybalt_2layer_{}_stats.csv\".format(latent_dim))\n",
    "hist_plot_file =os.path.join(os.path.dirname(os.getcwd()), \"stats\", \"tybalt_2layer_{}_hist.png\".format(latent_dim))\n",
    "encoded_file =os.path.join(os.path.dirname(os.getcwd()), \"encoded\", \"tybalt_2layer_encoded_{}.tsv\".format(latent_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------------------------------------------------------\n",
    "# Functions\n",
    "#\n",
    "# Based on publication by Greg et. al. \n",
    "# https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5728678/\n",
    "# https://github.com/greenelab/tybalt/blob/master/scripts/vae_pancancer.py\n",
    "# --------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Function for reparameterization trick to make model differentiable\n",
    "def sampling(args):\n",
    "\n",
    "    # Function with args required for Keras Lambda function\n",
    "    z_mean, z_log_var = args\n",
    "\n",
    "    # Draw epsilon of the same shape from a standard normal distribution\n",
    "    epsilon = K.random_normal(shape=tf.shape(z_mean), mean=0.,\n",
    "                              stddev=epsilon_std)\n",
    "\n",
    "    # The latent vector is non-deterministic and differentiable\n",
    "    # in respect to z_mean and z_log_var\n",
    "    z = z_mean + K.exp(z_log_var / 2) * epsilon\n",
    "    return z\n",
    "\n",
    "\n",
    "class CustomVariationalLayer(Layer):\n",
    "    \"\"\"\n",
    "    Define a custom layer that learns and performs the training\n",
    "    \"\"\"\n",
    "    def __init__(self, **kwargs):\n",
    "        # https://keras.io/layers/writing-your-own-keras-layers/\n",
    "        self.is_placeholder = True\n",
    "        super(CustomVariationalLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def vae_loss(self, x_input, x_decoded):\n",
    "        reconstruction_loss = original_dim * \\\n",
    "                              metrics.binary_crossentropy(x_input, x_decoded)\n",
    "        kl_loss = - 0.5 * K.sum(1 + z_log_var_encoded -\n",
    "                                K.square(z_mean_encoded) -\n",
    "                                K.exp(z_log_var_encoded), axis=-1)\n",
    "        return K.mean(reconstruction_loss + (K.get_value(beta) * kl_loss))\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = inputs[0]\n",
    "        x_decoded = inputs[1]\n",
    "        loss = self.vae_loss(x, x_decoded)\n",
    "        self.add_loss(loss, inputs=inputs)\n",
    "        # We won't actually use the output.\n",
    "        return x\n",
    "\n",
    "\n",
    "class WarmUpCallback(Callback):\n",
    "    def __init__(self, beta, kappa):\n",
    "        self.beta = beta\n",
    "        self.kappa = kappa\n",
    "\n",
    "    # Behavior on each epoch\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if K.get_value(self.beta) <= 1:\n",
    "            K.set_value(self.beta, K.get_value(self.beta) + self.kappa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------------------------------------------------------\n",
    "# Data initalizations\n",
    "# --------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Split 10% test set randomly\n",
    "test_set_percent = 0.1\n",
    "rnaseq_test_df = rnaseq.sample(frac=test_set_percent)\n",
    "rnaseq_train_df = rnaseq.drop(rnaseq_test_df.index)\n",
    "\n",
    "# Create a placeholder for an encoded (original-dimensional)\n",
    "rnaseq_input = Input(shape=(original_dim, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexj\\AppData\\Local\\conda\\conda\\envs\\Pa\\lib\\site-packages\\ipykernel_launcher.py:74: UserWarning: Output \"custom_variational_layer_1\" missing from loss dictionary. We assume this was done on purpose, and we will not be expecting any data to be passed to \"custom_variational_layer_1\" during training.\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------------------------------------------------------------\n",
    "# Architecture of VAE\n",
    "# --------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# ENCODER\n",
    "\n",
    "# Input layer is compressed into a mean and log variance vector of size\n",
    "# `latent_dim`. Each layer is initialized with glorot uniform weights and each\n",
    "# step (dense connections, batch norm,and relu activation) are funneled\n",
    "# separately\n",
    "# Each vector of length `latent_dim` are connected to the rnaseq input tensor\n",
    "\n",
    "# \"z_mean_dense_linear\" is the encoded representation of the input\n",
    "#    Take as input arrays of shape (*, original dim) and output arrays of shape (*, latent dim)\n",
    "#    Combine input from previous layer using linear summ\n",
    "# Normalize the activations (combined weighted nodes of the previous layer)\n",
    "#   Transformation that maintains the mean activation close to 0 and the activation standard deviation close to 1.\n",
    "# Apply ReLU activation function to combine weighted nodes from previous layer\n",
    "#   relu = threshold cutoff (cutoff value will be learned)\n",
    "#   ReLU function filters noise\n",
    "\n",
    "# X is encoded using Q(z|X) to yield mu(X), sigma(X) that describes latent space distribution\n",
    "hidden_dense_linear = Dense(intermediate_dim, kernel_initializer='glorot_uniform')(rnaseq_input)\n",
    "hidden_dense_batchnorm = BatchNormalization()(hidden_dense_linear)\n",
    "hidden_encoded = Activation('relu')(hidden_dense_batchnorm)\n",
    "\n",
    "# Note:\n",
    "# Normalize and relu filter at each layer adds non-linear component (relu is non-linear function)\n",
    "# If architecture is layer-layer-normalization-relu then the computation is still linear\n",
    "# Add additional layers in triplicate\n",
    "z_mean_dense_linear = Dense(latent_dim, kernel_initializer='glorot_uniform')(hidden_encoded)\n",
    "z_mean_dense_batchnorm = BatchNormalization()(z_mean_dense_linear)\n",
    "z_mean_encoded = Activation('relu')(z_mean_dense_batchnorm)\n",
    "\n",
    "z_log_var_dense_linear = Dense(latent_dim, kernel_initializer='glorot_uniform')(rnaseq_input)\n",
    "z_log_var_dense_batchnorm = BatchNormalization()(z_log_var_dense_linear)\n",
    "z_log_var_encoded = Activation('relu')(z_log_var_dense_batchnorm)\n",
    "\n",
    "# Customized layer\n",
    "# Returns the encoded and randomly sampled z vector\n",
    "# Takes two keras layers as input to the custom sampling function layer with a\n",
    "# latent_dim` output\n",
    "#\n",
    "# sampling():\n",
    "# randomly sample similar points z from the latent normal distribution that is assumed to generate the data,\n",
    "# via z = z_mean + exp(z_log_sigma) * epsilon, where epsilon is a random normal tensor\n",
    "# z ~ Q(z|X)\n",
    "# Note: there is a trick to reparameterize to standard normal distribution so that the space is differentiable and \n",
    "# therefore gradient descent can be used\n",
    "#\n",
    "# Returns the encoded and randomly sampled z vector\n",
    "# Takes two keras layers as input to the custom sampling function layer with a\n",
    "# latent_dim` output\n",
    "z = Lambda(sampling,\n",
    "           output_shape=(latent_dim, ))([z_mean_encoded, z_log_var_encoded])\n",
    "\n",
    "\n",
    "# DECODER\n",
    "\n",
    "# The decoding layer is much simpler with a single layer glorot uniform\n",
    "# initialized and sigmoid activation\n",
    "# Reconstruct P(X|z)\n",
    "decoder_model = Sequential()\n",
    "decoder_model.add(Dense(intermediate_dim, activation='relu', input_dim=latent_dim))\n",
    "decoder_model.add(Dense(original_dim, activation='sigmoid'))\n",
    "rnaseq_reconstruct = decoder_model(z)\n",
    "\n",
    "\n",
    "# CONNECTIONS\n",
    "# fully-connected network\n",
    "adam = optimizers.Adam(lr=learning_rate)\n",
    "vae_layer = CustomVariationalLayer()([rnaseq_input, rnaseq_reconstruct])\n",
    "vae = Model(rnaseq_input, vae_layer)\n",
    "vae.compile(optimizer=adam, loss=None, loss_weights=[beta])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1072 samples, validate on 119 samples\n",
      "Epoch 1/100\n",
      "1072/1072 [==============================] - 3s 3ms/step - loss: 3679.3090 - val_loss: 3584.1308\n",
      "Epoch 2/100\n",
      "1072/1072 [==============================] - 1s 1ms/step - loss: 3517.7427 - val_loss: 3644.5698\n",
      "Epoch 3/100\n",
      "1072/1072 [==============================] - 1s 1ms/step - loss: 3489.6239 - val_loss: 3595.3241\n",
      "Epoch 4/100\n",
      "1072/1072 [==============================] - 1s 964us/step - loss: 3479.3377 - val_loss: 3523.0185\n",
      "Epoch 5/100\n",
      "1072/1072 [==============================] - 1s 966us/step - loss: 3470.8499 - val_loss: 3497.1250\n",
      "Epoch 6/100\n",
      "1072/1072 [==============================] - 1s 943us/step - loss: 3466.7283 - val_loss: 3477.1256\n",
      "Epoch 7/100\n",
      "1072/1072 [==============================] - 1s 961us/step - loss: 3463.8264 - val_loss: 3489.6599\n",
      "Epoch 8/100\n",
      "1072/1072 [==============================] - 1s 982us/step - loss: 3457.2155 - val_loss: 3466.7768\n",
      "Epoch 9/100\n",
      "1072/1072 [==============================] - 1s 956us/step - loss: 3452.4075 - val_loss: 3468.4929\n",
      "Epoch 10/100\n",
      "1072/1072 [==============================] - 1s 948us/step - loss: 3447.5076 - val_loss: 3476.1474\n",
      "Epoch 11/100\n",
      "1072/1072 [==============================] - 1s 961us/step - loss: 3445.2571 - val_loss: 3456.9466\n",
      "Epoch 12/100\n",
      "1072/1072 [==============================] - 1s 1ms/step - loss: 3442.3367 - val_loss: 3458.4602\n",
      "Epoch 13/100\n",
      "1072/1072 [==============================] - 1s 1ms/step - loss: 3441.0336 - val_loss: 3458.0401\n",
      "Epoch 14/100\n",
      "1072/1072 [==============================] - 1s 1ms/step - loss: 3437.7915 - val_loss: 3458.1093\n",
      "Epoch 15/100\n",
      "1072/1072 [==============================] - 1s 1ms/step - loss: 3432.8532 - val_loss: 3449.2367\n",
      "Epoch 16/100\n",
      "1072/1072 [==============================] - 1s 1ms/step - loss: 3432.9851 - val_loss: 3447.9617\n",
      "Epoch 17/100\n",
      "1072/1072 [==============================] - 1s 1ms/step - loss: 3428.9426 - val_loss: 3450.8418\n",
      "Epoch 18/100\n",
      "1072/1072 [==============================] - 1s 967us/step - loss: 3424.7881 - val_loss: 3443.9900\n",
      "Epoch 19/100\n",
      "1072/1072 [==============================] - 1s 976us/step - loss: 3422.9817 - val_loss: 3438.8962\n",
      "Epoch 20/100\n",
      "1072/1072 [==============================] - 1s 963us/step - loss: 3420.8129 - val_loss: 3445.9902\n",
      "Epoch 21/100\n",
      "1072/1072 [==============================] - 1s 957us/step - loss: 3419.0926 - val_loss: 3443.6312\n",
      "Epoch 22/100\n",
      "1072/1072 [==============================] - 1s 980us/step - loss: 3415.1557 - val_loss: 3445.5024\n",
      "Epoch 23/100\n",
      "1072/1072 [==============================] - 1s 968us/step - loss: 3415.3225 - val_loss: 3438.8929\n",
      "Epoch 24/100\n",
      "1072/1072 [==============================] - 1s 961us/step - loss: 3413.2294 - val_loss: 3431.3945\n",
      "Epoch 25/100\n",
      "1072/1072 [==============================] - 1s 971us/step - loss: 3410.2513 - val_loss: 3429.6978\n",
      "Epoch 26/100\n",
      "1072/1072 [==============================] - 1s 960us/step - loss: 3408.1183 - val_loss: 3430.7380\n",
      "Epoch 27/100\n",
      "1072/1072 [==============================] - 1s 951us/step - loss: 3408.7164 - val_loss: 3423.0615\n",
      "Epoch 28/100\n",
      "1072/1072 [==============================] - 1s 995us/step - loss: 3406.7743 - val_loss: 3423.0126\n",
      "Epoch 29/100\n",
      "1072/1072 [==============================] - 1s 960us/step - loss: 3405.0378 - val_loss: 3415.8580\n",
      "Epoch 30/100\n",
      "1072/1072 [==============================] - 1s 1ms/step - loss: 3401.4919 - val_loss: 3421.9197\n",
      "Epoch 31/100\n",
      "1072/1072 [==============================] - 1s 1ms/step - loss: 3401.8999 - val_loss: 3416.7934\n",
      "Epoch 32/100\n",
      "1072/1072 [==============================] - 1s 1ms/step - loss: 3399.5713 - val_loss: 3418.9141\n",
      "Epoch 33/100\n",
      "1072/1072 [==============================] - 1s 1ms/step - loss: 3395.4296 - val_loss: 3412.7103\n",
      "Epoch 34/100\n",
      "1072/1072 [==============================] - 1s 1ms/step - loss: 3395.9318 - val_loss: 3412.1259\n",
      "Epoch 35/100\n",
      "1072/1072 [==============================] - 1s 1ms/step - loss: 3393.8758 - val_loss: 3420.3500\n",
      "Epoch 36/100\n",
      "1072/1072 [==============================] - 1s 1ms/step - loss: 3394.2139 - val_loss: 3412.9424\n",
      "Epoch 37/100\n",
      "1072/1072 [==============================] - 1s 1ms/step - loss: 3392.7002 - val_loss: 3408.9569\n",
      "Epoch 38/100\n",
      "1072/1072 [==============================] - 1s 1ms/step - loss: 3392.7558 - val_loss: 3407.8669\n",
      "Epoch 39/100\n",
      "1072/1072 [==============================] - 1s 965us/step - loss: 3390.8679 - val_loss: 3408.2137\n",
      "Epoch 40/100\n",
      "1072/1072 [==============================] - 1s 1ms/step - loss: 3391.3310 - val_loss: 3401.7357\n",
      "Epoch 41/100\n",
      "1072/1072 [==============================] - 1s 1ms/step - loss: 3389.7224 - val_loss: 3407.5343\n",
      "Epoch 42/100\n",
      "1072/1072 [==============================] - 1s 1ms/step - loss: 3389.1954 - val_loss: 3405.2423\n",
      "Epoch 43/100\n",
      "1072/1072 [==============================] - 1s 998us/step - loss: 3388.0447 - val_loss: 3406.9308\n",
      "Epoch 44/100\n",
      "1072/1072 [==============================] - 1s 992us/step - loss: 3386.7228 - val_loss: 3404.2078\n",
      "Epoch 45/100\n",
      "1072/1072 [==============================] - 1s 1ms/step - loss: 3385.7348 - val_loss: 3402.0022\n",
      "Epoch 46/100\n",
      "1072/1072 [==============================] - 1s 1ms/step - loss: 3384.7608 - val_loss: 3394.7882\n",
      "Epoch 47/100\n",
      "1072/1072 [==============================] - 1s 1ms/step - loss: 3383.0561 - val_loss: 3401.1987\n",
      "Epoch 48/100\n",
      "1072/1072 [==============================] - 1s 1ms/step - loss: 3379.5755 - val_loss: 3403.2685\n",
      "Epoch 49/100\n",
      "1072/1072 [==============================] - 2s 1ms/step - loss: 3381.6675 - val_loss: 3402.1881\n",
      "Epoch 50/100\n",
      "1072/1072 [==============================] - 1s 1ms/step - loss: 3379.2728 - val_loss: 3401.4965\n",
      "Epoch 51/100\n",
      "1072/1072 [==============================] - 1s 1ms/step - loss: 3382.1481 - val_loss: 3399.7808\n",
      "Epoch 52/100\n",
      "1072/1072 [==============================] - 1s 983us/step - loss: 3381.4720 - val_loss: 3400.0289\n",
      "Epoch 53/100\n",
      "1072/1072 [==============================] - 1s 989us/step - loss: 3378.7286 - val_loss: 3397.2536\n",
      "Epoch 54/100\n",
      "1072/1072 [==============================] - 1s 982us/step - loss: 3377.0258 - val_loss: 3399.2938\n",
      "Epoch 55/100\n",
      "1072/1072 [==============================] - 1s 986us/step - loss: 3375.5423 - val_loss: 3394.3041\n",
      "Epoch 56/100\n",
      "1072/1072 [==============================] - 1s 1ms/step - loss: 3376.7950 - val_loss: 3392.8653\n",
      "Epoch 57/100\n",
      "1072/1072 [==============================] - 1s 1ms/step - loss: 3375.7377 - val_loss: 3395.6286\n",
      "Epoch 58/100\n",
      "1072/1072 [==============================] - 1s 1ms/step - loss: 3374.9997 - val_loss: 3393.3587\n",
      "Epoch 59/100\n",
      "1072/1072 [==============================] - 1s 1ms/step - loss: 3376.1588 - val_loss: 3392.6869\n",
      "Epoch 60/100\n",
      "1072/1072 [==============================] - 1s 1ms/step - loss: 3373.7187 - val_loss: 3394.0003\n",
      "Epoch 61/100\n",
      "1072/1072 [==============================] - 1s 1ms/step - loss: 3371.6195 - val_loss: 3395.6287\n",
      "Epoch 62/100\n",
      "1072/1072 [==============================] - 1s 1ms/step - loss: 3373.7808 - val_loss: 3391.5941\n",
      "Epoch 63/100\n",
      "1072/1072 [==============================] - 1s 1ms/step - loss: 3372.3932 - val_loss: 3390.6912\n",
      "Epoch 64/100\n",
      "1072/1072 [==============================] - 1s 989us/step - loss: 3370.9308 - val_loss: 3388.6830\n",
      "Epoch 65/100\n",
      "1072/1072 [==============================] - 1s 1ms/step - loss: 3369.1670 - val_loss: 3394.1060\n",
      "Epoch 66/100\n",
      "1072/1072 [==============================] - 1s 1ms/step - loss: 3372.0136 - val_loss: 3389.9534\n",
      "Epoch 67/100\n",
      "1072/1072 [==============================] - 2s 1ms/step - loss: 3368.5093 - val_loss: 3392.6427\n",
      "Epoch 68/100\n",
      "1072/1072 [==============================] - 1s 1ms/step - loss: 3367.9085 - val_loss: 3394.4457\n",
      "Epoch 69/100\n",
      "1072/1072 [==============================] - 1s 1ms/step - loss: 3367.6258 - val_loss: 3390.0576\n",
      "Epoch 70/100\n",
      "1072/1072 [==============================] - 1s 1ms/step - loss: 3368.4298 - val_loss: 3388.1959\n",
      "Epoch 71/100\n",
      "1072/1072 [==============================] - 1s 1ms/step - loss: 3365.8257 - val_loss: 3386.9638\n",
      "Epoch 72/100\n",
      "1072/1072 [==============================] - 1s 1ms/step - loss: 3368.4099 - val_loss: 3385.1379\n",
      "Epoch 73/100\n",
      "1072/1072 [==============================] - 1s 1ms/step - loss: 3367.8942 - val_loss: 3390.2758\n",
      "Epoch 74/100\n",
      "1072/1072 [==============================] - 1s 1ms/step - loss: 3365.0328 - val_loss: 3383.9488\n",
      "Epoch 75/100\n",
      "1072/1072 [==============================] - 1s 1ms/step - loss: 3365.7339 - val_loss: 3386.9263\n",
      "Epoch 76/100\n",
      "1072/1072 [==============================] - 1s 1ms/step - loss: 3363.4251 - val_loss: 3385.1215\n",
      "Epoch 77/100\n",
      "1072/1072 [==============================] - 1s 1ms/step - loss: 3364.0030 - val_loss: 3383.2949\n",
      "Epoch 78/100\n",
      "1072/1072 [==============================] - 1s 959us/step - loss: 3364.7411 - val_loss: 3384.3990\n",
      "Epoch 79/100\n",
      "1072/1072 [==============================] - 1s 942us/step - loss: 3362.8814 - val_loss: 3382.2776\n",
      "Epoch 80/100\n",
      "1072/1072 [==============================] - 1s 941us/step - loss: 3362.5190 - val_loss: 3381.1832\n",
      "Epoch 81/100\n",
      "1072/1072 [==============================] - 1s 951us/step - loss: 3361.1368 - val_loss: 3382.1391\n",
      "Epoch 82/100\n",
      "1072/1072 [==============================] - 1s 961us/step - loss: 3362.0563 - val_loss: 3386.3806\n",
      "Epoch 83/100\n",
      "1072/1072 [==============================] - 1s 933us/step - loss: 3361.6833 - val_loss: 3380.0258\n",
      "Epoch 84/100\n",
      "1072/1072 [==============================] - 1s 942us/step - loss: 3362.0743 - val_loss: 3379.9421\n",
      "Epoch 85/100\n",
      "1072/1072 [==============================] - 1s 974us/step - loss: 3359.2240 - val_loss: 3379.2292\n",
      "Epoch 86/100\n",
      "1072/1072 [==============================] - 1s 936us/step - loss: 3360.0393 - val_loss: 3379.6126\n",
      "Epoch 87/100\n",
      "1072/1072 [==============================] - 1s 954us/step - loss: 3361.8350 - val_loss: 3378.7449\n",
      "Epoch 88/100\n",
      "1072/1072 [==============================] - 1s 941us/step - loss: 3358.0748 - val_loss: 3377.8587\n",
      "Epoch 89/100\n",
      "1072/1072 [==============================] - 1s 939us/step - loss: 3357.4276 - val_loss: 3380.8652\n",
      "Epoch 90/100\n",
      "1072/1072 [==============================] - 1s 934us/step - loss: 3356.7909 - val_loss: 3380.0950\n",
      "Epoch 91/100\n",
      "1072/1072 [==============================] - 1s 939us/step - loss: 3356.9738 - val_loss: 3378.8910\n",
      "Epoch 92/100\n",
      "1072/1072 [==============================] - 1s 951us/step - loss: 3357.2260 - val_loss: 3381.1522\n",
      "Epoch 93/100\n",
      "1072/1072 [==============================] - 1s 943us/step - loss: 3356.4243 - val_loss: 3380.6253\n",
      "Epoch 94/100\n",
      "1072/1072 [==============================] - 1s 942us/step - loss: 3355.3388 - val_loss: 3376.9261\n",
      "Epoch 95/100\n",
      "1072/1072 [==============================] - 1s 933us/step - loss: 3357.2358 - val_loss: 3375.8630\n",
      "Epoch 96/100\n",
      "1072/1072 [==============================] - 1s 1ms/step - loss: 3356.7090 - val_loss: 3374.5840\n",
      "Epoch 97/100\n",
      "1072/1072 [==============================] - 1s 965us/step - loss: 3355.9191 - val_loss: 3377.0522\n",
      "Epoch 98/100\n",
      "1072/1072 [==============================] - 1s 963us/step - loss: 3356.0879 - val_loss: 3374.8873\n",
      "Epoch 99/100\n",
      "1072/1072 [==============================] - 1s 930us/step - loss: 3353.8988 - val_loss: 3377.0775\n",
      "Epoch 100/100\n",
      "1072/1072 [==============================] - 1s 967us/step - loss: 3354.3722 - val_loss: 3372.9001\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------------------------------------------------------------------------------\n",
    "# Training\n",
    "# --------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# fit Model\n",
    "# hist: record of the training loss at each epoch\n",
    "hist = vae.fit(np.array(rnaseq_train_df), shuffle=True, epochs=epochs, batch_size=batch_size,\n",
    "               validation_data=(np.array(rnaseq_test_df), None),\n",
    "               callbacks=[WarmUpCallback(beta, kappa)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------------------------------------------------------\n",
    "# Use trained model to make predictions\n",
    "# --------------------------------------------------------------------------------------------------------------------\n",
    "encoder = Model(rnaseq_input, z_mean_encoded)\n",
    "\n",
    "encoded_rnaseq_df = encoder.predict_on_batch(rnaseq)\n",
    "encoded_rnaseq_df = pd.DataFrame(encoded_rnaseq_df, index=rnaseq.index)\n",
    "\n",
    "encoded_rnaseq_df.columns.name = 'sample_id'\n",
    "encoded_rnaseq_df.columns = encoded_rnaseq_df.columns + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x22c869729e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --------------------------------------------------------------------------------------------------------------------\n",
    "# Visualize training performance\n",
    "# --------------------------------------------------------------------------------------------------------------------\n",
    "history_df = pd.DataFrame(hist.history)\n",
    "ax = history_df.plot()\n",
    "ax.set_xlabel('Epochs')\n",
    "ax.set_ylabel('VAE Loss')\n",
    "fig = ax.get_figure()\n",
    "fig.savefig(hist_plot_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------------------------------------------------------\n",
    "# Output\n",
    "# --------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Save training performance\n",
    "history_df = pd.DataFrame(hist.history)\n",
    "history_df = history_df.assign(learning_rate=learning_rate)\n",
    "history_df = history_df.assign(batch_size=batch_size)\n",
    "history_df = history_df.assign(epochs=epochs)\n",
    "history_df = history_df.assign(kappa=kappa)\n",
    "history_df.to_csv(stat_file, sep='\\t')\n",
    "\n",
    "# Save latent space representation\n",
    "encoded_rnaseq_df.to_csv(encoded_file, sep='\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
